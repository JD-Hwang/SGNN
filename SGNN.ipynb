{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUg-XOLsMTQ0"
      },
      "source": [
        "# Scanner-Generalization Neural Networks (SGNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BUW6nUeEMTQ3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jivMerIBMTQ3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable, Function\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kESqicL9MTQ4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhzJBoaTMTQ4"
      },
      "source": [
        "## Assigning GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ne36EYLMTQ4"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXnGtn4AMTQ4",
        "outputId": "283fb0a6-dce0-46a7-f8ec-a487ef6cf4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHjEJrN9MTQ5"
      },
      "source": [
        "## Controling seed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c_-SoEPhMTQ5"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=0):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "seed_everything(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYJIzekgMTQ5"
      },
      "source": [
        "## Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PQpm4AQWMTQ6",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f560feb-00b1-4123-9e05-b62ea73f0c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 61776) (20, 2)\n"
          ]
        }
      ],
      "source": [
        "data = np.load(\"Sample_RSFC_p_factor_scanner.npz\", allow_pickle=True)\n",
        "X = data[\"X\"]\n",
        "y = data[\"y\"]\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6g0j-g6UMTQ6"
      },
      "outputs": [],
      "source": [
        "p_factor_idx, scanner_idx = 0, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T42__pAVMTQ6"
      },
      "outputs": [],
      "source": [
        "# Training dataset\n",
        "class TrainDataset(Dataset): \n",
        "    def __init__(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X_train)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        X_train = torch.from_numpy(self.X_train[idx]).type(torch.FloatTensor)\n",
        "        y_train = torch.from_numpy(self.y_train[idx]).type(torch.FloatTensor)\n",
        "\n",
        "        return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-mg7wOofMTQ7"
      },
      "outputs": [],
      "source": [
        "# Test dataset\n",
        "class ValidDataset(Dataset): \n",
        "    def __init__(self, X_valid, y_valid):\n",
        "        self.X_valid = X_valid\n",
        "        self.y_valid = y_valid\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X_valid)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        X_valid = torch.from_numpy(self.X_valid[idx]).type(torch.FloatTensor)\n",
        "        y_valid = torch.from_numpy(self.y_valid[idx]).type(torch.FloatTensor)\n",
        "        \n",
        "        return X_valid, y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y0ZpIJumMTQ7"
      },
      "outputs": [],
      "source": [
        "# Test dataset\n",
        "class TestDataset(Dataset): \n",
        "    def __init__(self, X_test, y_test):\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X_test)\n",
        "    \n",
        "    def __getitem__(self, idx): \n",
        "        X_test = torch.from_numpy(self.X_test[idx]).type(torch.FloatTensor)\n",
        "        y_test = torch.from_numpy(self.y_test[idx]).type(torch.FloatTensor)\n",
        "        \n",
        "        return X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdN_2CcEMTQ7"
      },
      "source": [
        "# Function for gradient reversal layer (Ganin et al., 2015)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-uDWbpVxMTQ7"
      },
      "outputs": [],
      "source": [
        "class GradRevFunc(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.clone()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grads):\n",
        "        lambda_ = ctx.lambda_\n",
        "        lambda_ = grads.new_tensor(lambda_)\n",
        "        dx = lambda_ * grads.neg()\n",
        "        return dx, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5jyVflsjMTQ7"
      },
      "outputs": [],
      "source": [
        "class GradRev(torch.nn.Module):\n",
        "    def __init__(self, lambda_=0.0):\n",
        "        super(GradRev, self).__init__()\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return GradRevFunc.apply(x, self.lambda_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOK2vsGkMTQ7"
      },
      "source": [
        "# Defining SGNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MIMG_e6dMTQ8"
      },
      "outputs": [],
      "source": [
        "class SGNN(nn.Module):\n",
        "    def __init__(self, fe_hidden, prd_hidden, dsc_hidden,\n",
        "                 dropout_fe, dropout_prd, dropout_dsc, act_func_name, lambda_):\n",
        "        super(SGNN, self).__init__()\n",
        "        self.fe_1 = nn.Linear(input_dim, fe_hidden)\n",
        "        self.fe_bn_1 = nn.BatchNorm1d(fe_hidden)\n",
        "        \n",
        "        self.prd_1 = nn.Linear(fe_hidden, prd_hidden)\n",
        "        self.prd_bn_1 = nn.BatchNorm1d(prd_hidden)\n",
        "        self.prd_2 = nn.Linear(prd_hidden, output_prd_dim)\n",
        "        \n",
        "        self.dsc_1 = nn.Linear(fe_hidden, dsc_hidden)\n",
        "        self.dsc_bn_1 = nn.BatchNorm1d(dsc_hidden)\n",
        "        self.dsc_2 = nn.Linear(dsc_hidden, output_dsc_dim)\n",
        "\n",
        "        self.dropout_fe = nn.Dropout(p=dropout_fe)\n",
        "        self.dropout_prd = nn.Dropout(p=dropout_prd)\n",
        "        self.dropout_dsc = nn.Dropout(p=dropout_dsc)\n",
        "        \n",
        "        self.act_func = get_act_func(act_func_name)\n",
        "        self.GradRev = GradRev(lambda_)\n",
        "        self.weights_init()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x_ftr = self.fe_1(x)\n",
        "        x_ftr = self.fe_bn_1(x_ftr)\n",
        "        x_ftr = self.act_func(x_ftr)\n",
        "        x_ftr = self.dropout_fe(x_ftr)\n",
        "        \n",
        "        x_prd = self.prd_1(x_ftr)\n",
        "        x_prd = self.prd_bn_1(x_prd)\n",
        "        x_prd = self.act_func(x_prd)\n",
        "        x_prd = self.dropout_prd(x_prd)\n",
        "        x_prd = self.prd_2(x_prd)\n",
        "        \n",
        "        x_rev = self.GradRev(x_ftr)\n",
        "        x_dsc = self.dsc_1(x_rev)\n",
        "        x_dsc = self.dsc_bn_1(x_dsc)\n",
        "        x_dsc = self.act_func(x_dsc)\n",
        "        x_dsc = self.dropout_dsc(x_dsc)\n",
        "        x_dsc = self.dsc_2(x_dsc)\n",
        "        \n",
        "        return x_prd, x_dsc\n",
        "    \n",
        "    def weights_init(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
        "                nn.init.normal_(m.bias, std=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nFISMmwDMTQ8"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, opt_name, learning_rate=None, l2_param=None):\n",
        "    lower_opt_name = opt_name.lower()\n",
        "    if lower_opt_name == 'momentum':\n",
        "        return optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                         momentum=momentum, weight_decay=l2_param)\n",
        "    elif lower_opt_name == 'nag':\n",
        "        return optim.SGD(model.parameters(), lr=learning_rate, \n",
        "                         momentum=momentum, weight_decay=l2_param, nesterov=True)\n",
        "    elif lower_opt_name == 'adam':\n",
        "        return optim.Adam(model.parameters(), lr=learning_rate, \n",
        "                          weight_decay=l2_param)\n",
        "    else:\n",
        "        sys.exit(\"Illegal arguement for optimizer type\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B3s989WUMTQ8"
      },
      "outputs": [],
      "source": [
        "def get_act_func(act_func_name):\n",
        "    act_func_name = act_func_name.lower()\n",
        "    if act_func_name == 'relu':\n",
        "        return nn.ReLU()\n",
        "    elif act_func_name == 'prelu':\n",
        "        return nn.PReLU()\n",
        "    elif act_func_name == 'elu':\n",
        "        return nn.ELU()\n",
        "    elif act_func_name == 'silu':\n",
        "        return nn.SiLU()\n",
        "    elif act_func_name == 'leakyrelu':\n",
        "        return nn.LeakyReLU()\n",
        "    elif act_func_name == 'tanh':\n",
        "        return nn.Tanh()\n",
        "    else:\n",
        "        sys.exit(\"Illegal arguement for activation function type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iyvFGoWMTQ8"
      },
      "source": [
        "# Functions for weight sparsity control with Hoyer's sparsness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BxEEBCxhMTQ8"
      },
      "outputs": [],
      "source": [
        "def init_hsp(n_wsc, epochs):\n",
        "    hsp_val = torch.zeros(n_wsc)\n",
        "    beta_val = torch.clone(hsp_val)\n",
        "    hsp_list = torch.zeros((n_wsc, epochs))\n",
        "    beta_list = torch.zeros((n_wsc, epochs))\n",
        "    \n",
        "    return hsp_val, beta_val, hsp_list, beta_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zV-40u7UMTQ8"
      },
      "outputs": [],
      "source": [
        "# Weight sparsity control with Hoyer's sparsness (Layer wise)\n",
        "def calc_hsp(w, beta, max_beta, beta_lr, tg_hsp):\n",
        "    \n",
        "    # Get value of weight\n",
        "    [dim, n_nodes] = w.shape\n",
        "    num_elements = dim * n_nodes\n",
        "    norm_ratio = torch.norm(w.detach(), 1) / torch.norm(w.detach(), 2)\n",
        "\n",
        "    # Calculate hoyer's sparsity level\n",
        "    num = math.sqrt(num_elements) - norm_ratio\n",
        "    den = math.sqrt(num_elements) - 1\n",
        "    hsp = torch.tensor(num / den).to(device)\n",
        "\n",
        "    # Update beta\n",
        "    beta = beta.clone() + beta_lr * torch.sign(torch.tensor(tg_hsp).to(device) - hsp)\n",
        "    \n",
        "    # Trim value\n",
        "    beta = 0 if beta < 0 else beta\n",
        "    beta = max_beta if beta > max_beta else beta\n",
        "\n",
        "    return [hsp, beta]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CHwYwwOSMTQ8"
      },
      "outputs": [],
      "source": [
        "def calc_l1(model, epoch, hsp_val, beta_val, hsp_list, beta_list, tg_hsp):\n",
        "    l1_reg = None\n",
        "    layer_idx = 0\n",
        "    wsc_idx = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"weight\" in name and \"bn\" not in name:\n",
        "            if \"fe\" in name or \"prd_1\" in name or \"dsc_1\" in name:\n",
        "                temp_w = param\n",
        "                \n",
        "                if wsc_flag[layer_idx] != 0:\n",
        "                    hsp_val[wsc_idx], beta_val[wsc_idx] = calc_hsp(\n",
        "                        temp_w, beta_val[wsc_idx], max_beta[wsc_idx], \n",
        "                        beta_lr[wsc_idx], tg_hsp[wsc_idx]\n",
        "                    )\n",
        "                    hsp_list[wsc_idx, epoch - 1] = hsp_val[wsc_idx]\n",
        "                    beta_list[wsc_idx, epoch - 1] = beta_val[wsc_idx]\n",
        "                    layer_reg = torch.norm(temp_w, 1) * beta_val[wsc_idx].clone()\n",
        "                    wsc_idx += 1\n",
        "                else:\n",
        "                    layer_reg = torch.norm(temp_w, 1) * l1_param\n",
        "\n",
        "                if l1_reg is None:\n",
        "                    l1_reg = layer_reg\n",
        "                else:\n",
        "                    l1_reg = l1_reg + layer_reg\n",
        "                layer_idx += 1\n",
        "        \n",
        "    return l1_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jo5Z5gCWMTQ8"
      },
      "outputs": [],
      "source": [
        "def calc_pearsonr(x, y):\n",
        "    x_mean = torch.mean(x)\n",
        "    y_mean = torch.mean(y)\n",
        "    xx = x.sub(x_mean)\n",
        "    yy = y.sub(y_mean)\n",
        "    num = xx.dot(yy)\n",
        "    den = torch.norm(xx, 2) * torch.norm(yy, 2)\n",
        "    corr = num / den\n",
        "    return corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vfIXh-_zMTQ9"
      },
      "outputs": [],
      "source": [
        "def calc_mae(x, y):\n",
        "    return torch.abs(x - y).mean().data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BsEpjDR0MTQ9"
      },
      "outputs": [],
      "source": [
        "def train(model, epoch, train_loader, optimizer, criterion_prd, criterion_dsc, \n",
        "          hsp_val, beta_val, hsp_list, beta_list, tg_hsp, lambda_, X_train, y_train):\n",
        "    model.train()\n",
        "    prd_loss = 0\n",
        "    dsc_loss = 0\n",
        "    dsc_acc = 0\n",
        "    cost = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    y_train_true = []\n",
        "    y_train_pred = []\n",
        "    \n",
        "    for batch_idx, (input, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        input, target = input.to(device), target.to(device)\n",
        "        output_prd, output_dsc = model(input)\n",
        "        target_prd = target[:, p_factor_idx].view(-1, 1)\n",
        "        target_dsc = target[:, scanner_idx].long().view(-1)\n",
        "        running_prd_loss = criterion_prd(output_prd, target_prd)\n",
        "        running_dsc_loss = criterion_dsc(output_dsc, target_dsc)\n",
        "        l1_norm = calc_l1(model, epoch, hsp_val, beta_val, hsp_list, beta_list, tg_hsp)\n",
        "        running_loss = running_prd_loss + running_dsc_loss + l1_norm.clone()\n",
        "\n",
        "        cost = running_loss\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        prd_loss += running_prd_loss.detach()\n",
        "        total += output_prd.size(0)\n",
        "        true_batch = torch.flatten(target_prd.detach())\n",
        "        pred_batch = torch.flatten(output_prd.detach())\n",
        "        y_train_true.append(true_batch)\n",
        "        y_train_pred.append(pred_batch)\n",
        "        \n",
        "    X_train = torch.from_numpy(X_train).type(torch.FloatTensor).to(device)\n",
        "    _, output_dsc = model(X_train)\n",
        "    _, scnr_pred = torch.max(output_dsc.data, 1)\n",
        "    scnr_pred = scnr_pred.detach().cpu().numpy().ravel()\n",
        "    scnr_true = y_train[:, scanner_idx].ravel()\n",
        "    dsc_acc = balanced_accuracy_score(scnr_true, scnr_pred)\n",
        "    \n",
        "    prd_loss /= total\n",
        "    dsc_loss /= total\n",
        "    y_train_true = torch.flatten(torch.stack(y_train_true))\n",
        "    y_train_pred = torch.flatten(torch.stack(y_train_pred))\n",
        "    train_corr = calc_pearsonr(y_train_true, y_train_pred)\n",
        "    train_mae = calc_mae(y_train_true, y_train_pred)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return prd_loss, dsc_loss, dsc_acc, train_corr, train_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "r1bOAbfBMTQ9"
      },
      "outputs": [],
      "source": [
        "def valid(model, epoch, valid_loader, criterion_prd, criterion_dsc, X_valid, y_valid):\n",
        "    model.eval()\n",
        "    prd_loss = 0\n",
        "    dsc_loss = 0\n",
        "    dsc_acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_valid_true = []\n",
        "    y_valid_pred = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for input, target in valid_loader:\n",
        "            input, target = input.to(device), target.to(device)\n",
        "            output_prd, output_dsc = model(input)\n",
        "            target_prd = target[:, p_factor_idx].view(-1, 1)\n",
        "            target_dsc = target[:, scanner_idx].long().view(-1)\n",
        "            running_dsc_loss = criterion_dsc(output_dsc, target_dsc)\n",
        "            running_prd_loss = criterion_prd(output_prd, target_prd)\n",
        "            dsc_loss += running_dsc_loss.detach()\n",
        "            prd_loss += running_prd_loss.detach()\n",
        "            total += output_prd.size(0)\n",
        "            _, pred = torch.max(output_dsc.data, 1)\n",
        "            correct += (pred.view(-1, 1) == target).sum().detach()\n",
        "            true_batch = torch.flatten(target_prd.detach())\n",
        "            pred_batch = torch.flatten(output_prd.detach())\n",
        "            y_valid_true.append(true_batch)\n",
        "            y_valid_pred.append(pred_batch)\n",
        "\n",
        "    X_valid = torch.from_numpy(X_valid).type(torch.FloatTensor).to(device)\n",
        "    _, output_dsc = model(X_valid)\n",
        "    _, scnr_pred = torch.max(output_dsc.data, 1)\n",
        "    scnr_pred = scnr_pred.detach().cpu().numpy().ravel()\n",
        "    scnr_true = y_valid[:, scanner_idx].ravel()\n",
        "    dsc_acc = balanced_accuracy_score(scnr_true, scnr_pred)\n",
        "\n",
        "    y_valid_true = torch.flatten(torch.stack(y_valid_true))\n",
        "    y_valid_pred = torch.flatten(torch.stack(y_valid_pred))\n",
        "    valid_corr = calc_pearsonr(y_valid_true, y_valid_pred)\n",
        "    valid_mae = calc_mae(y_valid_true, y_valid_pred)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return prd_loss, dsc_loss, dsc_acc, valid_corr, valid_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "txd9YdQ-MTQ9"
      },
      "outputs": [],
      "source": [
        "def test(model, epoch, test_loader, criterion_prd, criterion_dsc, X_test, y_test):\n",
        "    model.eval()\n",
        "    prd_loss = 0\n",
        "    total = 0\n",
        "    y_test_true = []\n",
        "    y_test_pred = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for input, target in test_loader:\n",
        "            input, target = input.to(device), target.to(device)\n",
        "            output_prd, output_clf = model(input)\n",
        "            target_prd = target[:, p_factor_idx].view(-1, 1)\n",
        "            running_prd_loss = criterion_prd(output_prd, target_prd)\n",
        "            prd_loss += running_prd_loss.detach()\n",
        "            total += output_prd.size(0)\n",
        "            true_batch = torch.flatten(target_prd.detach())\n",
        "            pred_batch = torch.flatten(output_prd.detach())\n",
        "            y_test_true.append(true_batch)\n",
        "            y_test_pred.append(pred_batch)\n",
        "\n",
        "    X_test = torch.from_numpy(X_test).type(torch.FloatTensor).to(device)\n",
        "    _, output_dsc = model(X_test)\n",
        "    _, scnr_pred = torch.max(output_dsc.data, 1)\n",
        "    scnr_pred = scnr_pred.detach().cpu().numpy().ravel()\n",
        "    scnr_true = y_test[:, scanner_idx].ravel()\n",
        "    dsc_acc = balanced_accuracy_score(scnr_true, scnr_pred)\n",
        "\n",
        "    y_test_true = torch.flatten(torch.stack(y_test_true))\n",
        "    y_test_pred = torch.flatten(torch.stack(y_test_pred))\n",
        "    test_corr = calc_pearsonr(y_test_true, y_test_pred)\n",
        "    test_mae = calc_mae(y_test_true, y_test_pred)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return prd_loss, test_corr, test_mae, dsc_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kToBQQjXMTQ9"
      },
      "outputs": [],
      "source": [
        "act_func_name = \"elu\"\n",
        "optimizer_name = \"nag\"\n",
        "\n",
        "fe_hidden = 100\n",
        "pp_hidden = 100\n",
        "scd_hidden = 100\n",
        "\n",
        "dropout_fe = 0.5\n",
        "dropout_pp = 0.5\n",
        "dropout_scd = 0.5\n",
        "\n",
        "batch_size = 4\n",
        "learning_rate = 1e-04\n",
        "epochs = 300\n",
        "\n",
        "l1_param = 0\n",
        "l2_param = 5e-02\n",
        "lmd = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "59lcEoACMTQ9"
      },
      "outputs": [],
      "source": [
        "momentum = 0.90\n",
        "input_dim = 61776\n",
        "n_classes = 2\n",
        "output_prd_dim = 1\n",
        "output_dsc_dim = n_classes\n",
        "\n",
        "wsc_flag = [1, 1, 1]\n",
        "tg_hsp_list = [[0.7], [0.3], [0.3]]\n",
        "beta_lr = [1e-04, 1e-03, 1e-03]\n",
        "max_beta = [1e-02, 5e-02, 5e-02]\n",
        "n_wsc = wsc_flag.count(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WXhihnA7MTQ9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y[:, scanner_idx], random_state=1000\n",
        ")\n",
        "\n",
        "train_dataset = TrainDataset(X_train, y_train)\n",
        "test_dataset = TestDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True, num_workers=4, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(y_test), pin_memory=True, shuffle=True, num_workers=4, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "U-smUUFMMTQ9"
      },
      "outputs": [],
      "source": [
        "model = SGNN(\n",
        "    fe_hidden, scd_hidden, pp_hidden, dropout_fe, dropout_pp, dropout_scd, act_func_name, lmd\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Zw5ExaP6MTQ9"
      },
      "outputs": [],
      "source": [
        "optimizer = get_optimizer(model, optimizer_name, learning_rate, l2_param)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,  step_size=10, gamma=0.5)\n",
        "criterion_prd = nn.MSELoss()\n",
        "criterion_dsc = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z3wuF8sMMTQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be8c261-60f6-4e6e-ddff-86bd7b0bb6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [300/300] Train corr: 0.8956, Test corr: 0.6678, Train loss: 0.0529, Test loss: 1.0377\n",
            "Layer 1: [0.7067/0.7000] Layer 2: [0.3037/0.3000] Layer 3: [0.3005/0.3000] Scanner classification accuracy : 43.65%\n"
          ]
        }
      ],
      "source": [
        "hsp_val, beta_val, hsp_list, beta_list = init_hsp(n_wsc, epochs)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    \n",
        "    train_prd_loss, train_dsc_loss, train_acc, train_corr, train_mae = train(\n",
        "        model, epoch, train_loader, optimizer, criterion_prd, criterion_dsc,\n",
        "        hsp_val, beta_val, hsp_list, beta_list, tg_hsp_list, lmd,\n",
        "        X_train, y_train\n",
        "    )\n",
        "\n",
        "    test_prd_loss, test_corr, test_mae, test_acc = test(\n",
        "        model, epoch, test_loader, criterion_prd, criterion_dsc, X_test, y_test\n",
        "    )\n",
        "\n",
        "    if epoch % 300 == 0:\n",
        "        print(\"\\nEpoch [{:d}/{:d}]\".format(epoch, epochs), end=\" \")\n",
        "        print(\"Train corr: {:.4f}, Test corr: {:.4f}, Train loss: {:.4f}, Test loss: {:.4f}\"\n",
        "              .format(train_corr, test_corr, train_prd_loss, test_prd_loss))\n",
        "        for i in range(len(wsc_flag)):\n",
        "            if wsc_flag[i] != 0:\n",
        "                print(\"Layer {:d}: [{:.4f}/{:.4f}]\".\n",
        "                      format( i + 1, hsp_val[i], tg_hsp_list[i][0]), end=\" \")\n",
        "        print(\"Scanner classification accuracy : {:.2f}%\".format(train_acc * 100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SGNN.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}